{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Necessary library","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport vtk\nimport cv2\nimport time\nimport pydicom\nimport numpy as np \nimport pandas as pd \nimport scipy.ndimage\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom glob import glob\nfrom skimage import measure\nfrom tensorflow import keras\nfrom plotly import __version__\nfrom plotly.graph_objs import*\nfrom skimage import morphology\nfrom vtk.util import numpy_support\nfrom sklearn.cluster import KMeans\nfrom skimage.transform import resize\nfrom IPython.display import clear_output\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom plotly.tools import FigureFactory as FF\nfrom tensorflow.keras.models import load_model\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom tensorflow.keras.callbacks import ModelCheckpoint as MC\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Data path setup","metadata":{}},{"cell_type":"code","source":"root_path ='../input/rsna-str-pulmonary-embolism-detection'\nfor item in os.listdir(root_path):\n    path = os.path.join(root_path, item)\n    if os.path.isfile(path):\n        print(path)\nprint(\"Reading the training dataset\")\ntrain = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/train.csv\")\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:36:41.82524Z","iopub.execute_input":"2021-08-10T14:36:41.825532Z","iopub.status.idle":"2021-08-10T14:36:46.008608Z","shell.execute_reply.started":"2021-08-10T14:36:41.825503Z","shell.execute_reply":"2021-08-10T14:36:46.007539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Dataset","metadata":{}},{"cell_type":"code","source":"print('Reading test data...')\ntest = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/test.csv\")\nprint(test.shape)\ntest.head()\n\nprint('Reading sample data...')\nss = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\nprint(ss.shape)\nss.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:36:46.01078Z","iopub.execute_input":"2021-08-10T14:36:46.011112Z","iopub.status.idle":"2021-08-10T14:36:46.33587Z","shell.execute_reply.started":"2021-08-10T14:36:46.011079Z","shell.execute_reply":"2021-08-10T14:36:46.334555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dicom file","metadata":{}},{"cell_type":"code","source":"reader = vtk.vtkDICOMImageReader()\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    _extent = reader.GetDataExtent()\n    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n    ConstPixelSpacing = reader.GetPixelSpacing()\n    imageData = reader.GetOutput()\n    pointData = imageData.GetPointData()\n    arrayData = pointData.GetArray(0)\n    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n    ArrayDicom = ArrayDicom.reshape(ConstPixelDims,order='F')\n    ArrayDicom = cv2.resize(ArrayDicom,(512,512))\n    return ArrayDicom\ndata_path =\"../input/rsna-str-pulmonary-embolism-detection/train/00511e94edec/297f170f1197\"\ndef load_scan(path):\n    slices = [pydicom.read_file(path+'/'+ s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2]-slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation-slices[1].SliceLocation)\n    for s in slices:\n        s.SliceThickness = slice_thickness\n    return slices\n\ndef get_pixels(scans):\n    image = np.stack([s.pixel_array for s in scans])\n    image = image.astype(np.int16)\n    image[image == -2000] = 0\n    intercept = scans[0].RescaleIntercept\n    slope = scans[0].RescaleSlope\n    if slope != 1:\n        image = slope*image.astype(np.float64)\n        image = image.astype(np.int16)\n    image += np.int16(intercept)\n    return np.array(image,dtype=np.int16)\nid=0\npatient = load_scan(data_path)\nimgs = get_pixels(patient)\noutput_dir = working_dir = \"./\"\nnp.save(output_dir + \"fullimages_%d.npy\"%(id),imgs)\nimport matplotlib.pyplot as plt\nfile_used=output_dir+\"fullimages_%d.npy\"%id\nimgs_to_process = np.load(file_used).astype(np.float64) \n\nplt.hist(imgs_to_process.flatten(), bins=20, color='g')\nplt.xlabel(\"Hounsfield Units\")\nplt.ylabel(\"Frequency\")\nplt.show()\nplt.savefig(\"ONE.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:36:46.338186Z","iopub.execute_input":"2021-08-10T14:36:46.338624Z","iopub.status.idle":"2021-08-10T14:36:50.575571Z","shell.execute_reply.started":"2021-08-10T14:36:46.338577Z","shell.execute_reply":"2021-08-10T14:36:50.574487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Dicom files","metadata":{}},{"cell_type":"code","source":"id = 0\nimgs_to_process = np.load(output_dir+'fullimages_{}.npy'.format(id))\ndef sample_stack(stack, rows=5, cols=5, start_with=50, show_every=5):\n    fig,ax = plt.subplots(rows,cols,figsize=[20,18])\n    for i in range(rows*cols):\n        index = start_with + i*show_every\n        ax[int(i/rows),int(i % rows)].set_title('Sadir FusFus %d'%index)\n        ax[int(i/rows),int(i % rows)].imshow(stack[index],cmap='binary')\n        ax[int(i/rows),int(i % rows)].axis('on')\n    plt.show()\n    plt.savefig(\"two.jpg\")\nsample_stack(imgs_to_process)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:36:50.577231Z","iopub.execute_input":"2021-08-10T14:36:50.577667Z","iopub.status.idle":"2021-08-10T14:36:54.369714Z","shell.execute_reply.started":"2021-08-10T14:36:50.577622Z","shell.execute_reply":"2021-08-10T14:36:54.368737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id = 0\nimgs_to_process = np.load(output_dir+'fullimages_{}.npy'.format(id))\ndef resample(image, scan, new_spacing=[1,1,1]):\n    spacing = map(float, ([scan[0].SliceThickness]+list(scan[0].PixelSpacing)))\n    spacing = np.array(list(spacing))\n    resize_factor = spacing/new_spacing\n    new_real_shape = image.shape*resize_factor\n    new_shape = np.round(new_real_shape)\n    real_resize_factor = new_shape/image.shape\n    new_spacing = spacing/real_resize_factor\n    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)\n    return image, new_spacing\nprint(\"Shape before resampling =\", imgs_to_process.shape)\nimgs_after_resamp, spacing = resample(imgs_to_process, patient, [1,1,1])\nprint(\"Shape after resampling =\", imgs_after_resamp.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:36:54.371199Z","iopub.execute_input":"2021-08-10T14:36:54.37174Z","iopub.status.idle":"2021-08-10T14:37:11.49675Z","shell.execute_reply.started":"2021-08-10T14:36:54.371698Z","shell.execute_reply":"2021-08-10T14:37:11.49566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Image Reader ","metadata":{}},{"cell_type":"code","source":"def make_mesh(image, threshold=-300, step_size=1):\n    print( \"Transposing surface\")\n    p = image.transpose(2,1,0)\n    print(\"Calculating surface\")\n    verts, faces, norm, val = measure.marching_cubes_lewiner(p, threshold, step_size=step_size, allow_degenerate=True) \n    return verts, faces\ndef plotly_3d(verts, faces):\n    x,y,z = zip(*verts) \n    print(\"Drawing\") \n    colormap=['rgb(200, 200, 245)','rgb(211, 136, 312)']\n    fig = FF.create_trisurf(x=x,\n                        y=y, \n                        z=z, \n                        plot_edges=False,\n                        colormap=colormap,\n                        simplices=faces,\n                        backgroundcolor='rgb(1,1,1)')\n    iplot(fig)\ndef plt_3d(verts,faces):\n    print(\"Drawing\")\n    x,y,z = zip(*verts) \n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n    mesh = Poly3DCollection(verts[faces], linewidths=0.05, alpha=1)\n    face_color = [1, 1, 0.9]\n    mesh.set_facecolor(face_color)\n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, max(x))\n    ax.set_ylim(0, max(y))\n    ax.set_zlim(0, max(z))\n    ax.set_facecolor((0.9, 0.4, 0.8))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:37:11.498479Z","iopub.execute_input":"2021-08-10T14:37:11.498938Z","iopub.status.idle":"2021-08-10T14:37:11.510888Z","shell.execute_reply.started":"2021-08-10T14:37:11.498889Z","shell.execute_reply":"2021-08-10T14:37:11.509893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v, f = make_mesh(imgs_after_resamp, 350)\nplt_3d(v, f)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:37:11.51355Z","iopub.execute_input":"2021-08-10T14:37:11.5139Z","iopub.status.idle":"2021-08-10T14:38:16.656694Z","shell.execute_reply.started":"2021-08-10T14:37:11.513868Z","shell.execute_reply":"2021-08-10T14:38:16.655463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Masking the unnecessary pixels","metadata":{}},{"cell_type":"code","source":"def make_lungmask(img,display=False):\n    row_size= img.shape[0]\n    col_size = img.shape[1]\n    mean = np.mean(img)\n    std = np.std(img)\n    img = img-mean\n    img = img/std\n    #average pixel value near the lungs to renormalize washed out images\n    middle = img[int(col_size/5):int(col_size/5*4),int(row_size/5):int(row_size/5*4)] \n    mean = np.mean(middle)  \n    max = np.max(img)\n    min = np.min(img)\n    img[img==max]=mean\n    img[img==min]=mean\n    # Using Kmeans to separate foreground (soft tissue,bone) and background (lung,air)\n    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n    centers = sorted(kmeans.cluster_centers_.flatten())\n    threshold = np.mean(centers)\n    thresh_img = np.where(img<threshold,1.5,0.0)\n    # First erode away the finer elements, then dilate to include some of the pixels surrounding the lung.We don't want to accidentally clip the lung.\n    eroded = morphology.erosion(thresh_img,np.ones([3,3]))\n    dilation = morphology.dilation(eroded,np.ones([8,8]))\n    labels = measure.label(dilation) # Different labels are displayed in different colors\n    label_vals = np.unique(labels)\n    regions = measure.regionprops(labels)\n    good_labels = []\n    for prop in regions:\n        B = prop.bbox\n        if B[2]-B[0]<row_size/10*9 and B[3]-B[1]<col_size/10*9 and B[0]>row_size/5 and B[2]<col_size/5*4:\n            good_labels.append(prop.label)\n    mask = np.ndarray([row_size,col_size],dtype=np.int8)\n    mask[:] = 0\n    #  After just the lungs are left, we do another large dilation in order to fill in and out the lung mask \n    for N in good_labels:\n        mask = mask + np.where(labels==N,1,0)\n    mask = morphology.dilation(mask,np.ones([10,10]))#last dialation\n    if (display):\n        fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n        ax[0, 0].set_title(\"Original\")\n        ax[0, 0].imshow(img, cmap='binary')\n        ax[0, 0].axis('on')\n        ax[0, 1].set_title(\"Threshold\")\n        ax[0, 1].imshow(thresh_img, cmap='gray')\n        ax[0, 1].axis('on')\n        ax[1, 0].set_title(\"After Erosion and Dilation\")\n        ax[1, 0].imshow(dilation, cmap='gray')\n        ax[1, 0].axis('on')\n        ax[1, 1].set_title(\"Color Labels\")\n        ax[1, 1].imshow(labels)\n        ax[1, 1].axis('on')\n        ax[2, 0].set_title(\"Final Mask\")\n        ax[2, 0].imshow(mask, cmap='gray')\n        ax[2, 0].axis('on')\n        ax[2, 1].set_title(\"Apply Mask on Original\")\n        ax[2, 1].imshow(mask*img, cmap='binary')\n        ax[2, 1].axis('on')\n        plt.show()\n    return mask*img\nimg = imgs_after_resamp[220]\nmake_lungmask(img,display=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:38:16.658447Z","iopub.execute_input":"2021-08-10T14:38:16.658773Z","iopub.status.idle":"2021-08-10T14:38:17.623317Z","shell.execute_reply.started":"2021-08-10T14:38:16.658741Z","shell.execute_reply":"2021-08-10T14:38:17.622135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Masked Image","metadata":{}},{"cell_type":"code","source":"masked_lung = []\nfor img in imgs_after_resamp:\n    masked_lung.append(make_lungmask(img))\nsample_stack(masked_lung, show_every=5)\nnp.save(output_dir + \"maskedimages_%d.npy\" % (id), imgs)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:38:17.624819Z","iopub.execute_input":"2021-08-10T14:38:17.625377Z","iopub.status.idle":"2021-08-10T14:38:54.581746Z","shell.execute_reply.started":"2021-08-10T14:38:17.62534Z","shell.execute_reply":"2021-08-10T14:38:54.580615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model","metadata":{}},{"cell_type":"code","source":"base_model = keras.applications.ResNet50(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=None,\n    pooling=None,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:38:54.583307Z","iopub.execute_input":"2021-08-10T14:38:54.583637Z","iopub.status.idle":"2021-08-10T14:38:56.52225Z","shell.execute_reply.started":"2021-08-10T14:38:54.583604Z","shell.execute_reply":"2021-08-10T14:38:56.521125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def identity_block(X, f, filters, stage, block):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n   \n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])# SKIP Connection\n    X = Activation('relu')(X)\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-08-10T10:51:27.744245Z","iopub.execute_input":"2021-08-10T10:51:27.744614Z","iopub.status.idle":"2021-08-10T10:51:27.755032Z","shell.execute_reply.started":"2021-08-10T10:51:27.744581Z","shell.execute_reply":"2021-08-10T10:51:27.754153Z"}}},{"cell_type":"markdown","source":"def convolutional_block(X, f, filters, stage, block, s=2):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-08-10T10:51:31.804564Z","iopub.execute_input":"2021-08-10T10:51:31.80495Z","iopub.status.idle":"2021-08-10T10:51:31.817629Z","shell.execute_reply.started":"2021-08-10T10:51:31.804914Z","shell.execute_reply":"2021-08-10T10:51:31.816476Z"}}},{"cell_type":"markdown","source":"# Model architecture","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential, Model,load_model\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\nfrom keras.preprocessing import image\nfrom keras.initializers import glorot_uniform\n\ninputs = Input((512, 512, 3))\nx = Conv2D(3, (1, 1), activation='relu')(inputs)\n\nbase_model = keras.applications.ResNet50(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=None,\n    pooling=None,\n)\nbase_model.trainable = False\n\noutputs = base_model(inputs, training=False)\noutputs = keras.layers.GlobalAveragePooling2D()(outputs)\noutputs = Dropout(0.25)(outputs)\noutputs = Dense(512, activation='relu')(outputs)\noutputs = Dense(256, activation='relu')(outputs)\noutputs = Dense(128, activation='relu')(outputs)\noutputs = Dense(64, activation='relu')(outputs)\noutputs = Dense(32, activation='relu')(outputs)\n\nppoi = Dense(1, activation='sigmoid', name='pe_present_on_image')(outputs)\nrlrg1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_gte_1')(outputs)\nrlrl1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_lt_1')(outputs) \nlspe = Dense(1, activation='sigmoid', name='leftsided_pe')(outputs)\ncpe = Dense(1, activation='sigmoid', name='chronic_pe')(outputs)\nrspe = Dense(1, activation='sigmoid', name='rightsided_pe')(outputs)\naacpe = Dense(1, activation='sigmoid', name='acute_and_chronic_pe')(outputs)\ncnpe = Dense(1, activation='sigmoid', name='central_pe')(outputs)\nindt = Dense(1, activation='sigmoid', name='indeterminate')(outputs)\n\nmodel = Model(inputs=inputs, outputs={'pe_present_on_image':ppoi,\n                                      'rv_lv_ratio_gte_1':rlrg1,\n                                      'rv_lv_ratio_lt_1':rlrl1,\n                                      'leftsided_pe':lspe,\n                                      'chronic_pe':cpe,\n                                      'rightsided_pe':rspe,\n                                      'acute_and_chronic_pe':aacpe,\n                                      'central_pe':cnpe,\n                                      'indeterminate':indt})\n\nopt = keras.optimizers.Adam(lr=0.0001)\nmodel.compile(optimizer=opt,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:38:56.52365Z","iopub.execute_input":"2021-08-10T14:38:56.524024Z","iopub.status.idle":"2021-08-10T14:38:59.0187Z","shell.execute_reply.started":"2021-08-10T14:38:56.523988Z","shell.execute_reply":"2021-08-10T14:38:59.017611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()\nmodel.save('pe_detection_model.h1')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:38:59.020336Z","iopub.execute_input":"2021-08-10T14:38:59.020777Z","iopub.status.idle":"2021-08-10T14:39:34.055184Z","shell.execute_reply.started":"2021-08-10T14:38:59.020727Z","shell.execute_reply":"2021-08-10T14:39:34.054088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"def convert_to_rgb(array):\n    array = array.reshape((512, 512, 1))\n    return np.stack([array, array, array], axis=2).reshape((512, 512, 3))\ndef custom_dcom_image_generator(batch_size, dataset, test=False, debug=False):\n    fnames = dataset[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']]\n    if not test:\n        Y = dataset[['pe_present_on_image', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1', 'leftsided_pe',\n                     'chronic_pe', 'rightsided_pe', 'acute_and_chronic_pe', 'central_pe', 'indeterminate'\n                    ]]\n        prefix = '../input/rsna-str-pulmonary-embolism-detection/train'\n\n    else:\n        prefix = '../input/rsna-str-pulmonary-embolism-detection/test'\n    X = []\n    batch = 0\n    for st, sr, so in fnames.values:\n        if debug:\n            print(f\"Current file: ../{prefix}/{st}/{sr}/{so}.dcm\")\n        dicom = get_img(f\"../{prefix}/{st}/{sr}/{so}.dcm\")\n        image = convert_to_rgb(dicom)\n        X.append(image)\n        del st, sr, so\n        if len(X) == batch_size:\n            if test:\n                yield np.array(X)\n                del X\n            else:\n                yield np.array(X), Y[batch*batch_size:(batch+1)*batch_size].values\n                del X\n            gc.collect()\n            X = []\n            batch += 1\n    if test:\n        yield np.array(X)\n    else:\n        yield np.array(X), Y[batch*batch_size:(batch+1)*batch_size].values\n        del Y\n    del X\n    gc.collect()\n    return","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:39:34.094715Z","iopub.execute_input":"2021-08-10T14:39:34.095365Z","iopub.status.idle":"2021-08-10T14:39:34.116295Z","shell.execute_reply.started":"2021-08-10T14:39:34.095303Z","shell.execute_reply":"2021-08-10T14:39:34.115357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = {}\nstart = time.time()\ndebug = 0\nbatch_size =1000\ntrain_size = int(batch_size*0.9)\nmax_train_time = 3600*10 \ncheckpoint = MC(filepath='../working/pe_detection_model.h1', monitor='val_loss', save_best_only=True, verbose=1)\n#Train loop\nfor n, (x, y) in enumerate(custom_dcom_image_generator(batch_size, train.sample(frac=1), False, debug)):\n    if len(x) < 10: #Tries to filter out empty or short data\n        break\n    clear_output(wait=True)\n    print(\"Training batch: %i - %i\" %(batch_size*n, batch_size*(n+1)))\n    model = load_model('../working/pe_detection_model.h1')\n    hist = model.fit(\n        x[:train_size], \n        {'pe_present_on_image':y[:train_size, 0],\n         'rv_lv_ratio_gte_1':y[:train_size, 1],\n         'rv_lv_ratio_lt_1':y[:train_size, 2],\n         'leftsided_pe':y[:train_size, 3],\n         'chronic_pe':y[:train_size, 4],\n         'rightsided_pe':y[:train_size, 5],\n         'acute_and_chronic_pe':y[:train_size, 6],\n         'central_pe':y[:train_size, 7],\n         'indeterminate':y[:train_size, 8]},\n        callbacks = checkpoint,\n        validation_split=0.2,\n        epochs=5,\n        batch_size=8,\n        verbose=debug\n    )\n    print(\"Metrics for batch validation:\")\n    model.evaluate(x[train_size:],\n                   {'pe_present_on_image':y[train_size:, 0],\n                    'rv_lv_ratio_gte_1':y[train_size:, 1],\n                    'rv_lv_ratio_lt_1':y[train_size:, 2],\n                    'leftsided_pe':y[train_size:, 3],\n                    'chronic_pe':y[train_size:, 4],\n                    'rightsided_pe':y[train_size:, 5],\n                    'acute_and_chronic_pe':y[train_size:, 6],\n                    'central_pe':y[train_size:, 7],\n                    'indeterminate':y[train_size:, 8]\n                   }\n                  )\n  \n    model.save('pe_detection_mode.h1')\n    del model, x, y\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:39:34.117745Z","iopub.execute_input":"2021-08-10T14:39:34.11811Z","iopub.status.idle":"2021-08-10T16:12:58.040372Z","shell.execute_reply.started":"2021-08-10T14:39:34.118057Z","shell.execute_reply":"2021-08-10T16:12:58.038153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}